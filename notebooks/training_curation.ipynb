{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224556ce-ca58-4cef-8c30-fb86e747fa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import polars as pl\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "252ca848-28bd-4f48-bd98-81daa11d5dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_prep(df_paths, emotions, primary_face, from_ntkb=True):\n",
    "    #  adjust paths if running frome notebooks dir (testing)\n",
    "    if from_ntkb:\n",
    "        df_paths = ['../' + path for path in df_paths]\n",
    "\n",
    "    df = pl.read_parquet(df_paths)\n",
    "    df = df.with_columns(\n",
    "        no_ext = pl.col('image_id').str.strip_suffix('.jpg')\n",
    "    )    \n",
    "    df = df.with_columns(\n",
    "        clean_id = pl.col('no_ext').str.split('_').list.last()\n",
    "    )\n",
    "\n",
    "    df = df.drop_nulls(subset=[\"face_path\"])\n",
    "    df = df.filter(pl.col(\"emotion\").is_in(emotions))\n",
    "    if primary_face:\n",
    "        df = df.filter(pl.col(\"face_index\") == 0)\n",
    "\n",
    "    #CHECK FOR DUPES \n",
    "    total_rows = len(df)\n",
    "    unique_rows = len(df.unique(subset=[\"clean_id\"]))\n",
    "    duplicates_count = total_rows - unique_rows\n",
    "    \n",
    "    print(f\"\\nTotal number of rows with duplicates in 'id' column (rows removed): {duplicates_count}\")\n",
    "    # Drop duplicate rows based on the \"id\" column, keeping the first occurrence\n",
    "    df = df.unique(subset=[\"clean_id\"], keep=\"first\")\n",
    "    \n",
    "    print(\"\\nDataFrame shape after dropping duplicates:\")\n",
    "    print(df.shape)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "956d6823-f6c2-4a74-93a6-993006b53adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_single_sources(config):\n",
    "    output_dir = Path(config['output_dir'])\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    emotions = config['emotions']\n",
    "    primary_face = config['primary_face']\n",
    "    \n",
    "    for name, path in config['single_sources'].items():\n",
    "        df = df_prep([path], emotions=emotions, primary_face=primary_face, from_ntkb=True)\n",
    "        out_file = name + '.parquet'\n",
    "        out_path = output_dir / out_file\n",
    "        df.write_parquet(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ac20904-612f-4bff-9b0b-dfdbc4b0a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = '../configs/aggregation_mixing/input_merging.json'\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5feee62e-5b46-4992-8aea-7c575a1b1461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output_dir': '../configs/aggregation_mixing',\n",
       " 'emotions': ['angry', 'fear', 'happy', 'sad', 'surprise'],\n",
       " 'primary_face': True,\n",
       " 'single_sources': {'pexels_v1': 'data/processed/pexels_v1/summaries/training_data.parquet',\n",
       "  'pexels_v2': 'data/processed/pexels_v2/summaries/training_data.parquet',\n",
       "  'pixabay_v1': 'data/processed/pixabay_v1/summaries/training_data.parquet',\n",
       "  'pixabay_v2': 'data/processed/pixabay_v2/summaries/training_data.parquet'},\n",
       " 'combine_sources': {'pexels_v3': ['pexels_v1', 'pexels_v2'],\n",
       "  'pixabay_v3': ['pixabay_v1', 'pixabay_v2'],\n",
       "  'pexpix_v1': ['pexels_v1', 'pixabay_v1'],\n",
       "  'pexpix_v2': ['pexels_v2', 'pixabay_v2'],\n",
       "  'pexpix_v3': ['pexels_v1', 'pixabay_v1', 'pexels_v2', 'pixabay_v2']},\n",
       " 'fer2013': '../data/fer-2013/',\n",
       " 'raf_db': '../data/raf-db/DATASET/'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a5ae5ae-afe6-416f-9d8a-263636967917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of rows with duplicates in 'id' column (rows removed): 0\n",
      "\n",
      "DataFrame shape after dropping duplicates:\n",
      "(2242, 24)\n",
      "\n",
      "Total number of rows with duplicates in 'id' column (rows removed): 0\n",
      "\n",
      "DataFrame shape after dropping duplicates:\n",
      "(4517, 24)\n",
      "\n",
      "Total number of rows with duplicates in 'id' column (rows removed): 0\n",
      "\n",
      "DataFrame shape after dropping duplicates:\n",
      "(1553, 24)\n",
      "\n",
      "Total number of rows with duplicates in 'id' column (rows removed): 0\n",
      "\n",
      "DataFrame shape after dropping duplicates:\n",
      "(2132, 24)\n"
     ]
    }
   ],
   "source": [
    "process_single_sources(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c026c9ee-21bc-4d23-a7f9-d578966b93b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_sources(config):\n",
    "    output_dir = Path(config['output_dir'])\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    emotions = config['emotions']\n",
    "    primary_face = config['primary_face']\n",
    "\n",
    "    for name, sources in config['combine_sources'].items():\n",
    "        input_files = []\n",
    "        for source in sources:\n",
    "            path = config[\"single_sources\"][source]\n",
    "            input_files.append(path)\n",
    "\n",
    "        df = df_prep(input_files, emotions=emotions, primary_face=primary_face, from_ntkb=True)\n",
    "        out_file = name + '.parquet'\n",
    "        out_path = output_dir / out_file\n",
    "        df.write_parquet(out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3186bf1b-742d-4b82-a6c6-ac909840c1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of rows with duplicates in 'id' column (rows removed): 923\n",
      "\n",
      "DataFrame shape after dropping duplicates:\n",
      "(5836, 24)\n",
      "\n",
      "Total number of rows with duplicates in 'id' column (rows removed): 549\n",
      "\n",
      "DataFrame shape after dropping duplicates:\n",
      "(3136, 24)\n",
      "\n",
      "Total number of rows with duplicates in 'id' column (rows removed): 0\n",
      "\n",
      "DataFrame shape after dropping duplicates:\n",
      "(3795, 24)\n",
      "\n",
      "Total number of rows with duplicates in 'id' column (rows removed): 1\n",
      "\n",
      "DataFrame shape after dropping duplicates:\n",
      "(6648, 24)\n",
      "\n",
      "Total number of rows with duplicates in 'id' column (rows removed): 1474\n",
      "\n",
      "DataFrame shape after dropping duplicates:\n",
      "(8970, 24)\n"
     ]
    }
   ],
   "source": [
    "combine_sources(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58a1e4fb-55f5-4c86-bd13-d062fbbdd6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_fer(config):\n",
    "    output_dir = Path(config['output_dir'])\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    emotions = config['emotions']\n",
    "    primary_face = config['primary_face']\n",
    "\n",
    "    fer_path = Path(config.get(\"fer2013\"))\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for usage_dir in fer_path.iterdir():\n",
    "        if not usage_dir.is_dir():\n",
    "                continue\n",
    "\n",
    "        usage = usage_dir.name\n",
    "\n",
    "        for emotion_dir in usage_dir.iterdir():\n",
    "            if not emotion_dir.is_dir():\n",
    "                continue\n",
    "                \n",
    "            emotion = emotion_dir.name\n",
    "            \n",
    "            for img_path in emotion_dir.glob('*.jpg'):\n",
    "                records.append({\n",
    "                    'data_source': \"fer2013\",\n",
    "                    'usage': usage,\n",
    "                    'emotion': emotion,\n",
    "                    'face_path': 'data/' + str(img_path.relative_to(fer_path.parent))\n",
    "                })    \n",
    "        \n",
    "    df = pl.DataFrame(records)\n",
    "    df.write_parquet(fer_path / \"all_images.parquet\")    \n",
    "\n",
    "    df = df.filter(pl.col(\"emotion\").is_in(emotions))\n",
    "    df.write_parquet(fer_path / \"selected_emotions_images.parquet\")    \n",
    "\n",
    "    train = df.filter(pl.col(\"usage\")==\"train\")\n",
    "    train.write_parquet(fer_path / \"train_images.parquet\")    \n",
    "    train.write_parquet(output_dir / \"fer_2013.parquet\")    \n",
    "    \n",
    "    test = df.filter(pl.col(\"usage\")==\"train\")\n",
    "    test.write_parquet(fer_path / \"test_images.parquet\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a8c307c-d4c9-4d3e-8c7c-ab7faefda0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_fer(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "248c2cce-b2a4-4c35-8ac7-791910b4227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_raf(config):\n",
    "    output_dir = Path(config['output_dir'])\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    emotions = config['emotions']\n",
    "    primary_face = config['primary_face']\n",
    "\n",
    "    raf_path = Path(config.get(\"raf_db\"))\n",
    "\n",
    "    records = []\n",
    "\n",
    "    for usage_dir in raf_path.iterdir():\n",
    "        if not usage_dir.is_dir():\n",
    "                continue\n",
    "\n",
    "        usage = usage_dir.name\n",
    "\n",
    "        for emotion_dir in usage_dir.iterdir():\n",
    "            if not emotion_dir.is_dir():\n",
    "                continue\n",
    "                \n",
    "            emotion = emotion_dir.name\n",
    "            \n",
    "            for img_path in emotion_dir.glob('*.jpg'):\n",
    "                records.append({\n",
    "                    'data_source': \"raf_db\",\n",
    "                    'usage': usage,\n",
    "                    'emotion': emotion,\n",
    "                    'face_path': 'data/' + str(img_path.relative_to(raf_path.parent.parent))\n",
    "                })    \n",
    "        \n",
    "    df = pl.DataFrame(records)\n",
    "    df.write_parquet(raf_path / \"all_images.parquet\")    \n",
    "\n",
    "    df = df.filter(pl.col(\"emotion\").is_in(emotions))\n",
    "    df.write_parquet(raf_path / \"selected_emotions_images.parquet\")    \n",
    "\n",
    "    train = df.filter(pl.col(\"usage\")==\"train\")\n",
    "    train.write_parquet(raf_path / \"train_images.parquet\")    \n",
    "    train.write_parquet(output_dir / \"raf_db.parquet\")    \n",
    "    \n",
    "    test = df.filter(pl.col(\"usage\")==\"train\")\n",
    "    test.write_parquet(raf_path / \"test_images.parquet\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09c2814d-31f9-4659-ba9c-7002c07c21e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_raf(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d942d09-0e37-444e-9ccb-fbb1fb37bc31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
